{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eecafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aeb08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Re-create the Text Cleaning Function from Notebook 1 ---\n",
    "# This is essential to ensure the input data matches the training data format.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e35b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models and cleaning function are ready.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load the trained models and tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_gatekeeper = AutoModelForSequenceClassification.from_pretrained(\"best-gatekeeper-model\")\n",
    "\n",
    "print(\"All models and cleaning function are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc278c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Build the CORRECTED Hierarchical Prediction Pipeline ---\n",
    "\n",
    "def predict_ticket_category(ticket_subject: str, ticket_description: str):\n",
    "    \"\"\"\n",
    "    Predicts the category of a support ticket using a hierarchical model pipeline.\n",
    "    It now correctly cleans the description text before making a prediction.\n",
    "    \"\"\"\n",
    "    # CORRECTED STEP: Clean the description text first\n",
    "    cleaned_description = clean_text(ticket_description)\n",
    "    \n",
    "    # Combine the subject with the CLEANED description\n",
    "    combined_text = f\"{ticket_subject} | {cleaned_description}\"\n",
    "    \n",
    "    # Tokenize the input text for the Gatekeeper model\n",
    "    inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # --- Gatekeeper Prediction ---\n",
    "    with torch.no_grad():\n",
    "        logits = model_gatekeeper(**inputs).logits\n",
    "    \n",
    "    gatekeeper_prediction_id = torch.argmax(logits, dim=1).item()\n",
    "    gatekeeper_prediction = model_gatekeeper.config.id2label[gatekeeper_prediction_id]\n",
    "    \n",
    "    # --- Decision Logic ---\n",
    "    if gatekeeper_prediction == 'Account Access':\n",
    "        return \"Account Access\"\n",
    "    else:\n",
    "        return \"Triage Required (Billing/General/Technical)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738fb1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test ticket 1: Account Access\n",
      "Prediction for test ticket 2: Triage Required (Billing/General/Technical)\n",
      "Prediction for test ticket 3: Triage Required (Billing/General/Technical)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Test the Pipeline Again ---\n",
    "# Example 1: A clear 'Account Access' ticket\n",
    "test_subject_1 = \"Account access\" # Using a subject the model has seen\n",
    "test_desc_1 = \"I have forgotten my password and the reset link is not working.\"\n",
    "prediction_1 = predict_ticket_category(test_subject_1, test_desc_1)\n",
    "print(f\"Prediction for test ticket 1: {prediction_1}\")\n",
    "\n",
    "# Example 2: A ticket that should go to triage\n",
    "test_subject_2 = \"Payment Issue\"\n",
    "test_desc_2 = \"My credit card was charged twice for the monthly subscription.\"\n",
    "prediction_2 = predict_ticket_category(test_subject_2, test_desc_2)\n",
    "print(f\"Prediction for test ticket 2: {prediction_2}\")\n",
    "\n",
    "# Example 3: Another triage case\n",
    "test_subject_3 = \"Software Bug\"\n",
    "test_desc_3 = \"The export feature is crashing the application every time I use it.\"\n",
    "prediction_3 = predict_ticket_category(test_subject_3, test_desc_3)\n",
    "print(f\"Prediction for test ticket 3: {prediction_3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
