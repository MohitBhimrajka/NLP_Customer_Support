{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Support Ticket Analysis - Data Exploration and Preprocessing\n",
    "\n",
    "This notebook explores and preprocesses customer support ticket data to prepare it for machine learning tasks. We'll examine the data structure, clean the text descriptions, and create a target variable for ticket categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll need several libraries for data manipulation, text processing, and natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f05b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "Let's start by loading the customer support tickets dataset and examining its basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359d340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "(8469, 17)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
      "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
      "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "3            Account access   \n",
      "4                 Data loss   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "3  I'm having an issue with the {product_purchase...   \n",
      "4  I'm having an issue with the {product_purchase...   \n",
      "\n",
      "               Ticket Status                                     Resolution  \\\n",
      "0  Pending Customer Response                                            NaN   \n",
      "1  Pending Customer Response                                            NaN   \n",
      "2                     Closed   Case maybe show recently my computer follow.   \n",
      "3                     Closed  Try capital clearly never color toward story.   \n",
      "4                     Closed                    West decision evidence bit.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
      "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n",
      "3                           3.0  \n",
      "4                           1.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('customer_support_tickets.csv')\n",
    "\n",
    "# 1. Shape of the DataFrame\n",
    "print(\"Shape of the dataset:\")\n",
    "print(df.shape)\n",
    "\n",
    "# 2. First 5 rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine Data Types and Missing Values\n",
    "\n",
    "Understanding the data structure helps us identify what preprocessing steps are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8979c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8469 entries, 0 to 8468\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Ticket ID                     8469 non-null   int64  \n",
      " 1   Customer Name                 8469 non-null   object \n",
      " 2   Customer Email                8469 non-null   object \n",
      " 3   Customer Age                  8469 non-null   int64  \n",
      " 4   Customer Gender               8469 non-null   object \n",
      " 5   Product Purchased             8469 non-null   object \n",
      " 6   Date of Purchase              8469 non-null   object \n",
      " 7   Ticket Type                   8469 non-null   object \n",
      " 8   Ticket Subject                8469 non-null   object \n",
      " 9   Ticket Description            8469 non-null   object \n",
      " 10  Ticket Status                 8469 non-null   object \n",
      " 11  Resolution                    2769 non-null   object \n",
      " 12  Ticket Priority               8469 non-null   object \n",
      " 13  Ticket Channel                8469 non-null   object \n",
      " 14  First Response Time           5650 non-null   object \n",
      " 15  Time to Resolution            2769 non-null   object \n",
      " 16  Customer Satisfaction Rating  2769 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 3. Summary information\n",
    "print(\"\\nDataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Ticket Status Distribution\n",
    "\n",
    "Understanding the current status of tickets helps us plan our analysis approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13f56c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Ticket Status:\n",
      "Ticket Status\n",
      "Pending Customer Response    2881\n",
      "Open                         2819\n",
      "Closed                       2769\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Status of tickets where Resolution is NaN:\n",
      "Ticket Status\n",
      "Pending Customer Response    2881\n",
      "Open                         2819\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of Ticket Status:\")\n",
    "print(df['Ticket Status'].value_counts())\n",
    "\n",
    "# Let's also see the status of tickets where Resolution is missing\n",
    "print(\"\\nStatus of tickets where Resolution is NaN:\")\n",
    "print(df[df['Resolution'].isnull()]['Ticket Status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore Ticket Types and Subjects\n",
    "\n",
    "Understanding the distribution of ticket types and subjects helps us design our categorization strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e08f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of Ticket Type:\n",
      "Ticket Type\n",
      "Refund request          1752\n",
      "Technical issue         1747\n",
      "Cancellation request    1695\n",
      "Product inquiry         1641\n",
      "Billing inquiry         1634\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 15 Ticket Subjects:\n",
      "Ticket Subject\n",
      "Refund request              576\n",
      "Software bug                574\n",
      "Product compatibility       567\n",
      "Delivery problem            561\n",
      "Hardware issue              547\n",
      "Battery life                542\n",
      "Network problem             539\n",
      "Installation support        530\n",
      "Product setup               529\n",
      "Payment issue               526\n",
      "Product recommendation      517\n",
      "Account access              509\n",
      "Peripheral compatibility    496\n",
      "Data loss                   491\n",
      "Cancellation request        487\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDistribution of Ticket Type:\")\n",
    "print(df['Ticket Type'].value_counts())\n",
    "\n",
    "print(\"\\nTop 15 Ticket Subjects:\")\n",
    "print(df['Ticket Subject'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert Date/Time Columns\n",
    "\n",
    "Converting string dates to datetime objects enables better time-based analysis and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8795c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information after converting date/time columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8469 entries, 0 to 8468\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Ticket ID                     8469 non-null   int64         \n",
      " 1   Customer Name                 8469 non-null   object        \n",
      " 2   Customer Email                8469 non-null   object        \n",
      " 3   Customer Age                  8469 non-null   int64         \n",
      " 4   Customer Gender               8469 non-null   object        \n",
      " 5   Product Purchased             8469 non-null   object        \n",
      " 6   Date of Purchase              8469 non-null   datetime64[ns]\n",
      " 7   Ticket Type                   8469 non-null   object        \n",
      " 8   Ticket Subject                8469 non-null   object        \n",
      " 9   Ticket Description            8469 non-null   object        \n",
      " 10  Ticket Status                 8469 non-null   object        \n",
      " 11  Resolution                    2769 non-null   object        \n",
      " 12  Ticket Priority               8469 non-null   object        \n",
      " 13  Ticket Channel                8469 non-null   object        \n",
      " 14  First Response Time           5650 non-null   datetime64[ns]\n",
      " 15  Time to Resolution            2769 non-null   datetime64[ns]\n",
      " 16  Customer Satisfaction Rating  2769 non-null   float64       \n",
      "dtypes: datetime64[ns](3), float64(1), int64(2), object(11)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Date of Purchase'] = pd.to_datetime(df['Date of Purchase'], errors='coerce')\n",
    "df['First Response Time'] = pd.to_datetime(df['First Response Time'], errors='coerce')\n",
    "df['Time to Resolution'] = pd.to_datetime(df['Time to Resolution'], errors='coerce')\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nDataset information after converting date/time columns:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Target Variable for Classification\n",
    "\n",
    "We'll create a new 'Category' column that groups tickets into meaningful classes for our machine learning model. This will serve as our target variable for ticket categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3acc49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the new 'Category' column:\n",
      "Category\n",
      "Billing            4778\n",
      "Technical Issue    1648\n",
      "General Query      1534\n",
      "Account Access      509\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the conditions and choices for our mapping\n",
    "conditions = [\n",
    "    df['Ticket Subject'] == 'Account access',\n",
    "    df['Ticket Type'].isin(['Billing inquiry', 'Refund request', 'Cancellation request']),\n",
    "    df['Ticket Type'] == 'Technical issue',\n",
    "    df['Ticket Type'] == 'Product inquiry'\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'Account Access',\n",
    "    'Billing',\n",
    "    'Technical Issue',\n",
    "    'General Query'\n",
    "]\n",
    "\n",
    "# Create the new 'Category' column\n",
    "df['Category'] = np.select(conditions, choices, default='Other') # Using 'Other' as a default just in case\n",
    "\n",
    "# Now, let's check the distribution of our new target variable\n",
    "print(\"Distribution of the new 'Category' column:\")\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Text Preprocessing Setup\n",
    "\n",
    "Before cleaning the text, we need to ensure NLTK resources are available. These provide stopwords and lemmatization capabilities for better text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c205837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to download these NLTK resources the first time you run this\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a7c9e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs. Cleaned Descriptions (first 5 rows):\n",
      "--- Ticket 1 ---\n",
      "Original:  I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "Your billing zip code is: 71701.\n",
      "\n",
      "We appreciate that you have requested a website address.\n",
      "\n",
      "Please double check your email address. I've tried troubleshooting steps mentioned in the user manual, but the issue persists.\n",
      "Cleaned:   issue productpurchased please assist billing zip code appreciate requested website address please double check email address ive tried troubleshooting step mentioned user manual issue persists\n",
      "\n",
      "--- Ticket 2 ---\n",
      "Original:  I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "If you need to change an existing product.\n",
      "\n",
      "I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "If The issue I'm facing is intermittent. Sometimes it works fine, but other times it acts up unexpectedly.\n",
      "Cleaned:   issue productpurchased please assist need change existing product issue productpurchased please assist issue facing intermittent sometimes work fine time act unexpectedly\n",
      "\n",
      "--- Ticket 3 ---\n",
      "Original:  I'm facing a problem with my {product_purchased}. The {product_purchased} is not turning on. It was working fine until yesterday, but now it doesn't respond.\n",
      "\n",
      "1.8.3 I really I'm using the original charger that came with my {product_purchased}, but it's not charging properly.\n",
      "Cleaned:   facing problem productpurchased productpurchased turning working fine yesterday doesnt respond really using original charger came productpurchased charging properly\n",
      "\n",
      "--- Ticket 4 ---\n",
      "Original:  I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "If you have a problem you're interested in and I'd love to see this happen, please check out the Feedback. I've already contacted customer support multiple times, but the issue remains unresolved.\n",
      "Cleaned:   issue productpurchased please assist problem youre interested love see happen please check feedback ive already contacted customer support multiple time issue remains unresolved\n",
      "\n",
      "--- Ticket 5 ---\n",
      "Original:  I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "\n",
      "Note: The seller is not responsible for any damages arising out of the delivery of the battleground game. Please have the game in good condition and shipped to you I've noticed a sudden decrease in battery life on my {product_purchased}. It used to last much longer.\n",
      "Cleaned:   issue productpurchased please assist note seller responsible damage arising delivery battleground game please game good condition shipped ive noticed sudden decrease battery life productpurchased used last much longer\n",
      "\n",
      "\n",
      "DataFrame info with the new 'Cleaned_Description' column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8469 entries, 0 to 8468\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Ticket ID                     8469 non-null   int64         \n",
      " 1   Customer Name                 8469 non-null   object        \n",
      " 2   Customer Email                8469 non-null   object        \n",
      " 3   Customer Age                  8469 non-null   int64         \n",
      " 4   Customer Gender               8469 non-null   object        \n",
      " 5   Product Purchased             8469 non-null   object        \n",
      " 6   Date of Purchase              8469 non-null   datetime64[ns]\n",
      " 7   Ticket Type                   8469 non-null   object        \n",
      " 8   Ticket Subject                8469 non-null   object        \n",
      " 9   Ticket Description            8469 non-null   object        \n",
      " 10  Ticket Status                 8469 non-null   object        \n",
      " 11  Resolution                    2769 non-null   object        \n",
      " 12  Ticket Priority               8469 non-null   object        \n",
      " 13  Ticket Channel                8469 non-null   object        \n",
      " 14  First Response Time           5650 non-null   datetime64[ns]\n",
      " 15  Time to Resolution            2769 non-null   datetime64[ns]\n",
      " 16  Customer Satisfaction Rating  2769 non-null   float64       \n",
      " 17  Category                      8469 non-null   object        \n",
      " 18  Cleaned_Description           8469 non-null   object        \n",
      "dtypes: datetime64[ns](3), float64(1), int64(2), object(13)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer and stopwords list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning steps to the input text.\n",
    "    \"\"\"\n",
    "    # 1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 3. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 4. Remove numbers (optional, but good for generalization)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # 5. Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 6. Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    # 7. Join tokens back into a string\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "# Apply the cleaning function to the 'Ticket Description' column\n",
    "# This might take a moment to run on all 8,469 rows\n",
    "df['Cleaned_Description'] = df['Ticket Description'].apply(clean_text)\n",
    "\n",
    "# Let's inspect the results\n",
    "print(\"Original vs. Cleaned Descriptions (first 5 rows):\")\n",
    "for i in range(5):\n",
    "    print(f\"--- Ticket {i+1} ---\")\n",
    "    print(\"Original: \", df['Ticket Description'].iloc[i])\n",
    "    print(\"Cleaned:  \", df['Cleaned_Description'].iloc[i])\n",
    "    print(\"\")\n",
    "\n",
    "# Also, let's check the DataFrame's info to see our new column\n",
    "print(\"\\nDataFrame info with the new 'Cleaned_Description' column:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff9272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed data has been saved to 'processed_customer_support_data.parquet'\n",
      "We are now ready to move on to Notebook 2 for model building.\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned and processed DataFrame to a file\n",
    "df.to_parquet('processed_customer_support_data.parquet', index=False)\n",
    "\n",
    "print(\"\\nProcessed data has been saved to 'processed_customer_support_data.parquet'\")\n",
    "print(\"We are now ready to move on to Notebook 2 for model building.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
